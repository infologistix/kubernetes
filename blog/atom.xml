<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://infologistix.github.io/kubernetes/blog</id>
    <title>KubeSpectra Blog</title>
    <updated>2022-10-20T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://infologistix.github.io/kubernetes/blog"/>
    <subtitle>KubeSpectra Blog</subtitle>
    <icon>https://infologistix.github.io/kubernetes/https://infologistix.de/wp-content/uploads/cropped-infologistix-Leistungsangebot-Data-Delivery-32x32.png</icon>
    <entry>
        <title type="html"><![CDATA[Test data sampling]]></title>
        <id>https://infologistix.github.io/kubernetes/blog/testdata</id>
        <link href="https://infologistix.github.io/kubernetes/blog/testdata"/>
        <updated>2022-10-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Before new applications go into production, data-driven tests are essential to ensure the quality of software and applications. For these tesings we have built a test data generator.]]></summary>
        <content type="html"><![CDATA[<p>Before new applications go into production, data-driven tests are essential to ensure the quality of software and applications. For these tesings we have built a test data generator.</p><p>Personal data is a core element of the entire business in many industries, e.g. insurance, banking and of course retail. The sensitive and highly-differentiated information stored here cannot be used for testing for data protection reasons. Instead, synthetic data is often used, the structure of which usually does not reflect the original data stock.</p><p>This means that realistic test conditions cannot be created. The result is significantly higher costs, because fixinings have to be installed during operation. In the worst case, this can even lead to acceptance problems among users and customers.</p><p><strong>What is needed instead is test data that is realistic and representative of the overall data stock.</strong> However, the creation of such test data means a lot of work in many cases, because dependencies have to be preserved, data types must not change, outliers need attention, personal data should not be used without pseudonomization, and so on.</p><p><strong>Therefore, we have developed a test data generator that creates a representative sample from a large original data set and then pseudonomizes it..</strong></p><p>Two different sampling methods can be selected, which we have evaluated in advance using statistical methods. Furthermore, different pseudonomizations are available. Finally, a download of the test data and a short report, with a comparison of the original and test data, are provided.</p><p>Currently, we have deployed the entire system as an on-demand site using Azure Functions. This means that when demand is high, more resources are kept available for as long as necessary. When demand drops, resources are reduced again. Therefore, loading the page can sometimes take a few seconds.</p><p>We are still in the testing phase of the <a href="https://kitestdataengine.azurewebsites.net/file_upload" target="_blank" rel="noopener noreferrer">test data generator</a>.</p>]]></content>
        <author>
            <name>Marie Padberg</name>
            <uri>https://github.com/MariePad</uri>
        </author>
        <category label="Python3" term="Python3"/>
        <category label="Azure" term="Azure"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[First Lecture of Cloud Native Computing]]></title>
        <id>https://infologistix.github.io/kubernetes/blog/lecture</id>
        <link href="https://infologistix.github.io/kubernetes/blog/lecture"/>
        <updated>2022-03-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Inaugural Lecture at the University of Applied Sciences Würzburg-Schweinfurt]]></summary>
        <content type="html"><![CDATA[<p>Inaugural Lecture at the University of Applied Sciences Würzburg-Schweinfurt</p><p>Just in time for the start of the summer semester 2022, our Head of Cloud Native Computing held his inaugural lecture as a lecturer at the <a href="https://de.linkedin.com/school/thws/" target="_blank" rel="noopener noreferrer">University of Applied Sciences Würzburg-Schweinfurt</a>.  </p><p>Dr.-Ing. Harald Gerhards supports the university as a lecturer in the newly accredited master's program "Artificial Intelligence". The focus of the elective module will be that students get to know cloud-native characteristics and architecture patterns and practice using important tools from the field (Docker, Kubernetes, Apache Kafka, Git and others).</p><p>As a certified Gold Partner of SUSE, infologistix has been working on building cloud-native platforms for our customers for several years. In this way, we create the conditions for scalability, fast adaptations of applications, near-real-time data analysis, AI-supported evaluations and much more for our customers.</p>]]></content>
        <category label="Cloud Native Computing" term="Cloud Native Computing"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Replication with Confluent Cloud]]></title>
        <id>https://infologistix.github.io/kubernetes/blog/data-Replication</id>
        <link href="https://infologistix.github.io/kubernetes/blog/data-Replication"/>
        <updated>2022-03-04T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache Kafka as a Service by Confluent]]></summary>
        <content type="html"><![CDATA[<p>Apache Kafka as a Service by Confluent</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h3><p>This article presents a proof of concept (PoC) of the group NewTechnologies@infologistix (NT) for cloud based replication (cbr) with Confluent cloud, the managed cloud service for Apache Kafka, and Microsoft Azure SQL databases, the database as a service on Microsoft Azure. The replication should be done by change data capture (CDC).
A combination of Confluent Cloud and managed Azure cloud services can be a really good choice for small enterprises as it provides the opportunity to develop serverless applications and therefore pay only for the data usage. That’s not the case when running Apache Kafka at your own data center or using other data streaming services on cloud platforms. And if your business will grow, you still stay flexible: At any point, it is possible to change subscription and get a dedicated cluster with private networking.  For situations that require dedicated clusters or a huge amount of data is shipped, Confluent Platform is probably the cheaper choices than Confluent Cloud.
<img loading="lazy" alt="High level structure of the PoC" src="/kubernetes/assets/images/confluent-kafka-poc-c51f83234cda0b3c305fce7cfd99ec85.png" width="1195" height="356" class="img_ev3q">
<em>Figure 1: High level structure of the PoC</em></p><p>The use case presented here, involves replicating data from a Azure SQL Database source to a Azure SQL Database target by applying the MS SQL server source and sink connector services of Confluent Cloud.  It’s a quit simple case, but a good way to get an impression how easy data replication and the usage of Confluent cloud can be. The whole configuration can be achieved just with the help of the Confluent and Microsoft Azure user interfaces. No coding is needed.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-by-step-to-serverless-data-replication">Step by step to serverless data replication<a href="#step-by-step-to-serverless-data-replication" class="hash-link" aria-label="Direct link to Step by step to serverless data replication" title="Direct link to Step by step to serverless data replication">​</a></h3><u> 1. Configuring Azure </u><p>Microsoft Azure offers a variety of managed services built for the cloud. First, let’s see how we can create databases.  For our use case we are going to need a source and a sink database on separate database servers for each one of them.</p><p><img loading="lazy" alt="Azure Portal dashboard" src="/kubernetes/assets/images/azure-portal-dashboard-40cac8a69a69b97b90525755f3768bb2.png" width="627" height="240" class="img_ev3q">
<em>Figure 2: Azure Portal dashboard</em></p><p>The first step is to log into the Azure portal. Then create a resource group. Here apart from the name of the group, the host region must be chosen. From the menu of the resource group, other services including the SQL database can be created and managed. </p><p><img loading="lazy" alt="Create a resource group instance" src="/kubernetes/assets/images/azure-portal-resource-group-aea25592c6240733327c5c3fc66eab06.png" width="644" height="364" class="img_ev3q">
<em>Figure 3: Create a resource group instance</em></p><p>But first an SQL Database server is required. So go back to the home directory and click-on the SQL Database server service. In the create menu, it is asked to assign the server to a valid resource group. The full name of the new server will be the given name plus the suffix “.database.windows.net”. Please keep that in mind for later configurations.  It is preferred to choose the same host location as the one for the resource group. In the authentication section, a username or so-called “Server admin login” and a password must be given. Finally, it is advised to allow the azure services and resources to access your server.</p><p><img loading="lazy" alt="Create an SQL Server instance in the Resource group" src="/kubernetes/assets/images/azure-sql-instance-3d445aa69c17dbf95de8bbdee5074e63.svg" width="654" height="344" class="img_ev3q">
<em>Figure 4: Create an SQL Server instance in the Resource group</em></p><p>Now all the infrastructure to set up the SQL database is available. It can be done at either the SQL server menu or the resource group menu. At the create menu, there are various options regarding  the storage, pricing and performance of the database connection to fit every need. It is again important to allow access to the azure services and to add the client IP address to the firewall. The rest of the networking configurations are meant mostly for advanced users. </p><p><img loading="lazy" alt="Create an SQL database instance in each SQL Server" src="/kubernetes/assets/images/azure-create-sql-database-fc34d3c55400573d41dcc1d4a811c99f.png" width="605" height="277" class="img_ev3q">
<em>Figure 5: Create an SQL database instance in each SQL Server</em></p><p>In this PoC the source SQL server is called  “nt-cbr-sqlserver” whereas the sink server “nt-cbr-sqlserver-dest”. The corresponding source database is called CloudBasedReplication_Source and the sink database “CloudBasedReplication_Target”. The server username is “Infologistix”. This info will be used to configure the confluent cloud connectors.</p><p><img loading="lazy" alt="Resource group Menu" src="/kubernetes/assets/images/azure-resource-group-menu-f303dcefb92cd94a6ea86b650f85d42a.png" width="638" height="337" class="img_ev3q">
<em>Figure 6: Resource group Menu</em></p><p>The database data can be accessed from the query editor inside the database menu or from an external client (e.g SQL Server Management Studio (SSMS)). Activity logs, properties and other information can also be found in the menu. To illustrate the data replication, a table “orderdetails” with the following structure is created in the “CloudBasedReplication_Source” database and is filled with some data:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">CREATE TABLE orderdetails(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">"ORDER_NUMBER" int identity (1,1) PRIMARY KEY,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">"PRODUCT_CODE" int,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">"QUANTITY_ORDERED" float,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">"PRICE_EACH" decimal(10,5),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">"CREATED_AT" datetime2 DEFAULT CURRENT_TIMESTAMP NOT NULL)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Attention:</strong> The timestamp column must always be of type datetime2. Other formats are not supported.</p><u> 2. Configuring Confluent Cloud </u><p>The initial step in the confluent cloud environment is to set up a cluster. One can choose between three providers: AWS, Google Cloud and Azure. Obviously, for this use case we are going to choose the Azure provider. Furthermore, the host region and the subscription type must be chosen. A basic subscription is enough in this case. For new accounts, a free trial of 2 months and consumption up to 400 US Dollars is offered. </p><p><img loading="lazy" alt="Create Cluster page" src="/kubernetes/assets/images/cluster-page-a00a907dd5083a769050f8b6c01e8af2.png" width="639" height="317" class="img_ev3q">
<em>Figure 7: Create Cluster page</em></p><p><img loading="lazy" alt="Confluent Cloud Cluster dashboard" src="/kubernetes/assets/images/cluster-dashboard-31c7b5113e2d5f0437cf8e1a648ec450.png" width="756" height="338" class="img_ev3q">
<em>Figure 8: Confluent Cloud Cluster dashboard</em></p><p>Next, a schema at the environment dashboard needs to be defined. The Avro schema should be chosen.
Now, click-on the cluster menu. The first thing is to create an API Key to authenticate the cluster. The API key username and password should be saved during its generation. Afterwards there is no way to retrieve the password. </p><p><img loading="lazy" alt="Schema Registry overview" src="/kubernetes/assets/images/schema-registry-overview-c81bf17792c7e9d7115fbb46a6bfe772.png" width="659" height="271" class="img_ev3q">
<em>Figure 9: Schema Registry overview</em></p><p><img loading="lazy" alt="Create API-Key page" src="/kubernetes/assets/images/api-key-page-82f2887fd3411c694a24b0e4194197ce.png" width="673" height="266" class="img_ev3q">
<em>Figure 10: Create API-Key page</em></p><p>Now it is time to set up the SQL server source and sink connectors. There is a huge variety of connectors, so it is easier to use the search bar. Each field in the configuration interface has a sufficient explanation, but there are some details that need to be treated with more care.   </p><p><img loading="lazy" alt="Kafka Connector list" src="/kubernetes/assets/images/kafka-connector-list-e9ed0dfe42568f63349668cd88c44447.png" width="1498" height="603" class="img_ev3q">
<em>Figure 11: Kafka Connector list</em></p><u>Source Connector</u><p>First we will add and configure the source connector:
<img loading="lazy" alt="Add connector page" src="/kubernetes/assets/images/kafka-add-connector-0ae90d790f07ee8358a627939a10ea42.png" width="629" height="288" class="img_ev3q">
<em>Figure 12:  Add connector page</em></p><p>The following screenshot shows the source connector’s configuration used in this example. Only the fields with a given value are visible here. The rest can be left empty, which means they will hold the default value:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">       Source Connector Configuration:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">{</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connector.class": "MicrosoftSqlServerSource",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "name": "MicrosoftSqlServerSourceConnector_0",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "kafka.api.key": "****************",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "kafka.api.secret": "****************************************************************",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "topic.prefix": "src",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connection.host": "nt-cbr-sqlserver.database.windows.net",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connection.port": "1433",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connection.user": "Infologistix@nt-cbr-sqlserver",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "db.name": "CloudBasedReplication_Source",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "table.whitelist": [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    "orderdetails"</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "timestamp.column.name": [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    "CREATED_AT"</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "incrementing.column.name": "",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "table.types": [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    "TABLE"</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "db.timezone": "Europe/Brussels",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "numeric.mapping": "best_fit",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "output.data.format": "AVRO",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "tasks.max": "1"</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The name and the login credentials of the source database and server, which were created in Azure, must be given here. The example names are used to show you how to fill in the blanks correctly. The source connector creates automatically a topic with the prefix “src” plus the initial table name “orderdetails”, which serializes the table data with the Avro schema and acts like a Kafka producer. One should be careful with the prefix and table names, as specific characters might cause connector failure. The bad thing is that the confluent error messages
might not identify the true cause of this problem. Underscores and dots are prohibited, whereas dash is allowed.</p><u>Sink connector</u><p>When adding the sink connector, proceed in the same way as for the source connector.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">   Sink Connector Configuration:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">{</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "topics": [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    "srcorderdetails"</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "input.data.format": "AVRO",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connector.class": "MicrosoftSqlServerSink",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "name": "MicrosoftSqlServerSinkConnector_0",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "kafka.api.key": "****************",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "kafka.api.secret": "****************************************************************",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connection.host": "nt-cbr-sqlserver-dest.database.windows.net",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connection.port": "1433",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "connection.user": "Infologistix@nt-cbr-sqlserver-dest",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "db.name": "CloudBasedReplication_Target",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "insert.mode": "INSERT",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "db.timezone": "Europe/Brussels",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "pk.mode": "none",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "auto.create": "true",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "auto.evolve": "true",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "batch.sizes": "1000",</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  "tasks.max": "1"</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The name and the login credentials of the sink database need to be given here. Input format is AVRO. The sink connector consumes data from the topic “srcorderdetails” and load them into a table in the target database with the same name. Messages which cannot be loaded into the target are transferred it into a newly created Dead Letter Topic (in our case “dlq-lcc-50d8z”). Since the “auto.create” field is true, the table in the target Database is automatically created.
This should be the overview of the connector and topic sections by now. If the schema does not seem to be set for a topic, it can be manually set:</p><p><img loading="lazy" alt="Topics dashboard after all connections are set" src="/kubernetes/assets/images/topics-1143031b26ccbca42bff135fdd1e3710.png" width="852" height="203" class="img_ev3q">
<em>Figure 13: Topics dashboard after all connections are set</em></p><p>First we will add and configure the source connector:
<img loading="lazy" alt="Connector’s dashboard  after all connections are set" src="/kubernetes/assets/images/connectors-d6ecca0775d94aa8f04553dcdcfc80c6.png" width="845" height="202" class="img_ev3q">
<em>Figure 14: Connector’s dashboard  after all connections are set</em></p><p>The data flow can be seen at section “Stream lineage” as below:</p><p><img loading="lazy" alt="Data flow" src="/kubernetes/assets/images/flow-0acb116d17cd2ec9f3e80d849f1e7f7a.png" width="817" height="233" class="img_ev3q">
<em>Figure 15: Data flow</em></p><p>Data are now present in the sink database:</p><p>First we will add and configure the source connector:
<img loading="lazy" alt="View newly transferred data in query editor  " src="/kubernetes/assets/images/transferred-data-f1769edc53318e7e594f33620702d6a8.png" width="756" height="307" class="img_ev3q">
<em>Figure 16: View newly transferred data in query editor</em></p><u>Troubleshooting</u><p>Sometimes the connectors fail to run at first. If the error is unexpected then deleting and recreating can help. It can also happen that the error disappears after a couple of minutes by itself.</p><u>A few remarks about cdc connectors</u><p>Now, every time new data arrives at the source database, they will be directly processed and stored at the sink database. It should be noted though, that this is true only for rows with a timestamp value greater than the one of the last fetch. If more than one timestamp columns is defined in the source connector configuration, then the first non-null value will be considered. Same applies to modified rows. They are simply dealt as new rows, rather than updated.</p><p><strong>Info:</strong> The SQL server connectors are constantly upgraded to offer more options to the user. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3><p>Our proof of concept was able to show that it is extremely easy to use the functionality of Apache Kafka with the Confluent Cloud. A data replication for a table could be realized in a few minutes. However, the Confluent Cloud also offers the possibility to perform transformations through the integration of KSQL, so that ETL operations are also possible. In addition, this also enables problem-free changes of the SQL dialect, since date formats can be adapted through simple transformations. Scenarios in which an on premise database (e.g. IBM DB2 or Oracle DB) is replicated via confluent cloud and is then backed up in the Azure Cloud are therefore also no problem.
We hope we have been able to give you a small insight into the possibilities of managed cloud services from our partners Confluent and Microsoft and make it easier for you to get started with cloud computing.</p>]]></content>
        <author>
            <name>Harald P. Gerhards</name>
            <uri>https://github.com/HPG84</uri>
        </author>
        <author>
            <name>Emmanouil Goulidakis</name>
            <uri>https://github.com/Chainsaw7</uri>
        </author>
        <category label="Confluent" term="Confluent"/>
        <category label="Kafka" term="Kafka"/>
        <category label="Azure" term="Azure"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker in WSL]]></title>
        <id>https://infologistix.github.io/kubernetes/blog/docker-in-wsl</id>
        <link href="https://infologistix.github.io/kubernetes/blog/docker-in-wsl"/>
        <updated>2022-01-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Docker Desktop becomes commercial, we show you a free alternative - Docker in Windows Subsystem for Linux (WSL)]]></summary>
        <content type="html"><![CDATA[<p>Docker Desktop becomes commercial, we show you a free alternative - Docker in Windows Subsystem for Linux (WSL)</p><p>Docker's free products are used by millions of developers to build, publish and run applications - in data centers, the public cloud or with Docker Desktop on the local PC.
55% of developers use Docker every day at work.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="docker-desktop-becomes-commercially-viable">Docker Desktop becomes commercially viable<a href="#docker-desktop-becomes-commercially-viable" class="hash-link" aria-label="Direct link to Docker Desktop becomes commercially viable" title="Direct link to Docker Desktop becomes commercially viable">​</a></h4><p>But the Docker Company also needs to be profitable and has decided to charge enterprise customers as part of a business model redesign. Starting Jan. 31, 2022, any use of Docker Desktop will be chargeable for users at companies with more than 250 employees or more than $10 million in annual revenue. A subscription will then cost between $7 and $21 per user per month, depending on which services are widely used and how they are paid for. For enterprises and government agencies, this raises the question of whether Docker Desktop is worth the monthly fee or if there are other options.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="docker-deamon-and-docker-client-remain-free-and-open-source-foss">Docker Deamon and Docker Client remain free and open source (FOSS)<a href="#docker-deamon-and-docker-client-remain-free-and-open-source-foss" class="hash-link" aria-label="Direct link to Docker Deamon and Docker Client remain free and open source (FOSS)" title="Direct link to Docker Deamon and Docker Client remain free and open source (FOSS)">​</a></h4><p>In addition to the GUI, which will be paid for in the future, the Docker software stack consists of free, open source components that do the actual work. The Docker Client is a command-line tool that serves the Docker Daemon API. The Docker Deamon is at the heart of the container runtime environment. On Linux, these can be installed and used natively and free of charge.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-ways-under-windows-with-infologistix">New ways under Windows with infologistix<a href="#new-ways-under-windows-with-infologistix" class="hash-link" aria-label="Direct link to New ways under Windows with infologistix" title="Direct link to New ways under Windows with infologistix">​</a></h4><p>On Microsoft Windows 10 and Windows 11, on the other hand, you have to take a slightly more elaborate route to escape the licensing model and continue using Docker for free on your local PC. But at infologistix, we've made managing these tools as easy as using the Internet. Copying from large data centers where Linux servers run Docker as FOSS, we use these same tools for the local development environment.</p><p><strong>We've made installing Docker as simple as running an installer after enabling and installing the Windows Subsystem for Linux. As a bonus, you can install the Docker client yourself on your local machine by downloading it and configuring a Docker context to use the internally hosted Docker platform on Windows Subsystem for Linux.</strong></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="lets-go">Let's go<a href="#lets-go" class="hash-link" aria-label="Direct link to Let's go" title="Direct link to Let's go">​</a></h3><h5 class="anchor anchorWithStickyNavbar_LWe7" id="installing-wsl2">Installing WSL2<a href="#installing-wsl2" class="hash-link" aria-label="Direct link to Installing WSL2" title="Direct link to Installing WSL2">​</a></h5><p>The first step to running Docker native on a Linux kernel even on Windows 10 or Windows 11 is to enable the new Windows Subsystem for Linux (WSL2):</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="current-builds">Current Builds<a href="#current-builds" class="hash-link" aria-label="Direct link to Current Builds" title="Direct link to Current Builds">​</a></h5><p>If you are running Windows 10, version 2004 and above (build 19041 and above), or Windows 11 you can simply open your power shell as administrator and run the following command:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ wsl --install</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This command enables the required optional Windows components, downloads the latest Linux kernel, sets WSL 2 as the default, and installs a Linux distribution for you (Ubuntu by default). To change the installed distribution, type the following:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ wsl --install -d &lt;Distribution Name&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Replace &lt; Distribution Name &gt;  with the name of the distribution you want to install.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="older-builds">Older builds<a href="#older-builds" class="hash-link" aria-label="Direct link to Older builds" title="Direct link to Older builds">​</a></h5><p>Windows 10 offered Windows Subsystem for Linux (WSL) version 1 starting with the Fall Creators Update (version 1709). WSL2 is available after extended backward compatibility starting with build 18363.1049. For the following steps, we always refer to the 64-bit variant of PowerShell.</p><p>The first thing to do is to enable WSL as a Windows feature. To do this, call PowerShell as administrator and activate the feature:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Before installing WSL 2, you must enable the optional Virtual Computer Platform feature.</p><p>Open PowerShell as an administrator and run the following:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Then restart the computer.</p><p>Now install the WSL update package. To do this, download the latest update package from  <a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi" target="_blank" rel="noopener noreferrer">https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi</a>. Run the update package downloaded in the previous step.</p><p>Now start a PowerShell (without administrator rights) and execute the following to set WSL2 as default version.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ wsl --set-default-version 2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Open the Microsoft Store and select your preferred Linux distribution. Our script and the procedure described here are supported:</p><ul><li>Debian</li><li>Ubuntu</li><li>OpenSUSE</li></ul><p>When you start a newly installed Linux distribution for the first time, a console window will open and you will be prompted to wait until the files have been decompressed and saved to the computer. All future launches should take less than a second.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="infologistix-docker-installer-für-wsl2">Infologistix Docker Installer für WSL2<a href="#infologistix-docker-installer-für-wsl2" class="hash-link" aria-label="Direct link to Infologistix Docker Installer für WSL2" title="Direct link to Infologistix Docker Installer für WSL2">​</a></h3><p><img loading="lazy" alt="Structure of the infologistix Docker solution" src="/kubernetes/assets/images/docker-wsl-aufbau-4aa218026063c6a3248c2ac665625aa4.png" width="607" height="409" class="img_ev3q">
<em>Figure 1: Structure of the infologistix Docker solution</em></p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="installation">Installation<a href="#installation" class="hash-link" aria-label="Direct link to Installation" title="Direct link to Installation">​</a></h5><p>Docker can be installed within WSL2 using the following bash command:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ bash &lt;(curl -fsSL https://raw.githubusercontent.com/infologistix/docker-wsl2/main/install.sh)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h5 class="anchor anchorWithStickyNavbar_LWe7" id="using-docker-on-windows">Using Docker on Windows<a href="#using-docker-on-windows" class="hash-link" aria-label="Direct link to Using Docker on Windows" title="Direct link to Using Docker on Windows">​</a></h5><p>On Windows, add the path variable. The installer will install a Docker client to <strong>C:\Docker\docker.exe</strong>. This path must be specified once, then Docker is also present in Windows. </p><p>The usage is then done with a docker context:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ docker context create wsldocker --docker host=tcp://localhost:2375</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ docker context use wsldocker</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h5 class="anchor anchorWithStickyNavbar_LWe7" id="uninstall">Uninstall<a href="#uninstall" class="hash-link" aria-label="Direct link to Uninstall" title="Direct link to Uninstall">​</a></h5><p>Docker can be uninstalled with the following bash command inside WSL2:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ bash &lt;(curl -fsSL https://raw.githubusercontent.com/infologistix/docker-wsl2/main/uninstall.sh)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3><p>In summary, we have combined and created an installer for running Docker in a Windows Subsystem for Linux environment. The resulting installer, additional configuration, and documentation can be found in our GitHub repository: </p><p><a href="https://github.com/infologistix/docker-wsl2" target="_blank" rel="noopener noreferrer">infologistix/docker-wsl2: Simple and fast Docker Integration in WSL2 without using Docker Desktop. Suitable for large enterprises</a></p>]]></content>
        <author>
            <name>Suphanat Avipan</name>
            <uri>https://github.com/suphanataviphan</uri>
        </author>
        <author>
            <name>Harald P. Gerhards</name>
            <uri>https://github.com/HPG84</uri>
        </author>
        <author>
            <name>Nico Graap</name>
            <uri>https://github.com/Nico-infologistix</uri>
        </author>
        <author>
            <name>Paul Schmidt</name>
            <uri>https://github.com/pickmylight</uri>
        </author>
        <category label="Docker" term="Docker"/>
        <category label="WSL" term="WSL"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Use Case for a WebCrawler]]></title>
        <id>https://infologistix.github.io/kubernetes/blog/webcrawler</id>
        <link href="https://infologistix.github.io/kubernetes/blog/webcrawler"/>
        <updated>2021-07-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[WebCrawlers are a simple, effective and inexpensive way to search websites for specific information and make it available in compressed form. The programs are thus ideally suited to perform repetitive tasks.]]></summary>
        <content type="html"><![CDATA[<p>WebCrawlers are a simple, effective and inexpensive way to search websites for specific information and make it available in compressed form. The programs are thus ideally suited to perform repetitive tasks.
In this article, we present a use case for a WebCrawler and give you a detailed how-to on setting up a cloud-based Docker.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="webcrawler---use-case">WebCrawler - Use Case<a href="#webcrawler---use-case" class="hash-link" aria-label="Direct link to WebCrawler - Use Case" title="Direct link to WebCrawler - Use Case">​</a></h3><p>WebCrawlers are lightweight and cost-effective data collectors that give you an information edge. Nowadays, (almost) all information is available online. Googling has become synonymous with finding information, from a simple cooking recipe to a scientific paper.</p><p>Most of this data is freely available and can be easily accessed. However, the sheer volume of data and websites makes a search very time-consuming and labor-intensive. The time required is particularly important if the search is not to be carried out just once, but on a regular basis, so that changes and developments can be monitored. Here, so-called WebCrawlers offer themselves as a simple and, above all, cost-efficient way to automate the search.</p><p>WebCrawlers are programs that automatically search the Internet and analyze websites. They are therefore perfectly suited for repetitive tasks.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="example">Example<a href="#example" class="hash-link" aria-label="Direct link to Example" title="Direct link to Example">​</a></h4><p>At infologistix GmbH, we use WebCrawler for various tasks, including monitoring public tender sites and filtering out the tenders that are of interest to us. For this purpose we crawl about two dozen different websites of public authorities, companies and portals. Here, crawling means that a cloud-based <u>Docker</u> calls up the pages one after the other, searches them for interesting tenders and provides us with a result list containing only relevant tenders. Technical details, as well as the Docker image and instructions for rebuilding it, can be found in the <a href="#webcrawler---how-to">How-To section</a> below.</p><p>The results list of relevant RFPs represents a huge time and cost savings for us. Instead of having to search through hundreds of RFPs per day, we now only have to review half a dozen RFPs. And this at only about 1€ operating costs per week for the WebCrawler.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="resumé">Resumé<a href="#resumé" class="hash-link" aria-label="Direct link to Resumé" title="Direct link to Resumé">​</a></h4><p>WebCrawlers are a simple, effective and inexpensive way to search websites for specific information and to make the results available in compressed form. Our Docker image is a particularly lightweight and easy-to-use variant. If you have any questions about WebCrawlers or are looking for a customized solution, please feel free to contact us.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="webcrawler---how-to">WebCrawler - How-To<a href="#webcrawler---how-to" class="hash-link" aria-label="Direct link to WebCrawler - How-To" title="Direct link to WebCrawler - How-To">​</a></h3><p>With this How-To we show how to set up a cloud-based Docker to crawl websites for information and provide prepared search results via notification over social chat like MS Teams or Slack or even email.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="what-you-need">What you need<a href="#what-you-need" class="hash-link" aria-label="Direct link to What you need" title="Direct link to What you need">​</a></h4><ul><li>Local Docker runtime</li><li>Social chat (MS Teams, Slack) or email client</li><li><a href="https://hub.docker.com/r/infologistix/docker-selenium-python" target="_blank" rel="noopener noreferrer">infologistix WebCrawler from Docker Hub</a></li><li>Some experience with <a href="https://www.python.org/" target="_blank" rel="noopener noreferrer">Python</a>, Command Line, HTML</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="for-using-in-the-cloud-optionally">For using in the cloud optionally:<a href="#for-using-in-the-cloud-optionally" class="hash-link" aria-label="Direct link to For using in the cloud optionally:" title="Direct link to For using in the cloud optionally:">​</a></h4><ul><li><a href="https://azure.microsoft.com/en-us/" target="_blank" rel="noopener noreferrer">Microsoft Azure</a></li><li><a href="https://aws.amazon.com/" target="_blank" rel="noopener noreferrer">Amazon AWS</a></li><li><a href="https://cloud.google.com/" target="_blank" rel="noopener noreferrer">Google Cloud Platform</a></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="lets-get-started">Let's get started<a href="#lets-get-started" class="hash-link" aria-label="Direct link to Let's get started" title="Direct link to Let's get started">​</a></h4><u> 0. Clone GitHub repository </u><p>This How-To is based on a project structure, which we have already created and which you can transfer directly into your project. Under the following link you can also find this how-to as a <strong>finished program in the Examples folder.</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ git clone https://github.com/infologistix/docker-selenium-python.git ./infologistix</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Let's look at a simple example here and first find out what services our company offers. The functions shown here can be easily adapted to new circumstances.</p><u> 1. Basic structure and libraries </u><p>The test framework Selenium already provides us with a wide range of functions and equipment to target websites and to determine information. The basic structure of our project is based on a class that handles the communication with the browser and extracts all data from the website for us. In addition, we use pandas as a tool for formatting and data analysis of the search results.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from selenium.webdriver import Chrome</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from selenium.webdriver import ChromeOptions </span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from selenium.webdriver.support.ui import WebDriverWait</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from selenium.webdriver.common.by import By</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from selenium.webdriver.support import expected_conditions as EC</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas as pd</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Based on the libraries used, we can write a base class for our crawler. This base class describes the general crawler. We use the class representation, because here the website and its functions and element extraction can be called as variables and functions. Initially, we hereby open a Chrome window in "headless" mode and open the given web page.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">class InfologistixCrawler():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, url: str, headless: bool=True) -&gt; None:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        options = ChromeOptions()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        options.add_argument("–no-sandbox")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        options.add_argument("–window-size=1280,720")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        if headless:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            options.add_argument("–headless")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.driver = Chrome(options=options)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.driver.get(url)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def run(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        page = self.driver.page_source</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.close()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return page</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def close(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.driver.close()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><u> 2. Determine information of the website </u><p>We filter out the services offered from our own <a href="https://infologistix.de/" target="_blank" rel="noopener noreferrer">homepage</a> and want to store them with name, details and reference. To do this, we look for the information on the website and determine the basic HTML structure. In our case, the services are in a 'section' element, which we need to find. Our searched element has the ID 'services', which in turn contains several 'section' elements with the class attribute 'elementor-image-box-content'. All the services are stored here.</p><p>First, we wait until the element we are looking for exists. We use WebDrverWait to tell our program to wait a maximum of 10 seconds for our requested element to be present on the web page in the DOM. If this element is not present, then we get out of the running program here and we don't run into any errors.</p><p>Then we save the container with the searched elements using the find_element_by<!-- -->*<!-- --> function and search within this container with find_elements_by* all searched elements and extract the single information of the extraction.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def getServices(self) -&gt; list:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        results = list()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.ID, "Leistungen")))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        services = self.driver.find_element_by_id ("Leistungen")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        for service in services.find_elements_by_tag_name("section"):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            results.append(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                 self.__extract(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                          service.find_element_by_class_name(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                   "elementor-image-box-content")))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">         return results</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>As a result we get a list, which we only have to return. What exactly the function __extract() does, we will explain in a moment.</p><p>With the help of the list we can now develop a representation of the individual services, which simplifies the visibility and readability for humans. We choose here the representation of a Pandas DatenFrames, because here, for example, numerical calculations and aggregations can be made. In addition, Excel files can also be created from this. So we create a DataFrame with the columns "URI", "Title" and "Description" from our list, which contains the title, description and the respective reference.</p><p>A DataFrame is then returned.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def makeFrame(self, services: list) -&gt; pd.DataFrame:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return pd.DataFrame(services)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Based on this transformation of the results, we rearrange our run() function so that it gives us the results it finds and includes the functions it creates.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def run(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     services = self.getServices()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     self.close()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     return self.makeFrame(services)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Let's remember back to our __extract() function. Here we want to extract the required information from the elements. Finding out and filtering relevant information is the main task here. All the information is present in different elements with different identifiers. For example, the title is text within an 'a' element, which also contains the reference. In our example, the extraction function is composed as follows and returns us an ordered dictionary containing the element information.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def __extract(self, service: WebElement) -&gt; dict:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           "URI": service.find_element_by_tag_name("a").get_attribute("href"),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           "Title": service.find_element_by_tag_name("a").text,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           "Description": service.find_element_by_tag_name("p").text,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">         }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The entire class with functions then looks like this:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">class InfologistixCrawler():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, url, headless=False):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        options = ChromeOptions()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        options.add_argument("–no-sandbox")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        options.add_argument("–window-size=1280,720")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        if headless:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            options.add_argument("–headless")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.driver = Chrome(options=options)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.driver.get(url)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def getServices(self) -&gt; list:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        results = list()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.ID, "Leistungen")))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        services = self.driver.find_element_by_id ("Leistungen")</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        for service in services.find_elements_by_tag_name("section"):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            results.append(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                 self.__extract(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                          service.find_element_by_class_name(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                   "elementor-image-box-content")))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return results</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __extract(self, service: WebElement) -&gt; dict:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           "URI": service.find_element_by_tag_name("a").get_attribute("href"),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           "Title": service.find_element_by_tag_name("a").text,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           "Description": service.find_element_by_tag_name("p").text,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">         }</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def makeFrame(self, services : list) -&gt; pd.DataFrame:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return pd.DataFrame(services)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def run(self) -&gt; pd.DataFrame:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        services = self.getServices()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.close()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return self.makeFrame(services)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def close(self) -&gt; None:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.driver.close()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>If we let our crawler run, we get a DataFrame with the offered services of infologistix GmbH.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">services = Crawler(url="https://infologistix.de").run()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We can now extract the infologistix GmbH services from the website and output them as a dataframe. The next step is the transmission of the results.</p><u> 3. Submission &amp; Messaging </u>For Teams, as well as Slack, a token and webhook respectively is used to send a formatted message to a channel. Unfortunately, the integration of Slack is not yet fully implemented and can therefore lead to errors.<p><a href="https://dev.outlook.com/Connectors/GetStarted#creating-messages-through-office-365-connectors-in-microsoft-teams" target="_blank" rel="noopener noreferrer">Here you can find detailed instructions on how to get a webhook of a channel in MS Teams.</a></p><p>Here we use the base library pymsteams and create a card with the webhook URL available to us. We add a title and the search results formatted as HTML to the post and send it to our Teams channel.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pymsteams</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">message = services.to_html()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">title = "Dienstleistungen Infologistix"</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def sendMSTeams(webhook : str, message : str, title : str) -&gt; Literal[True]:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    channel = pymsteams.connectorcard(webhook)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    channel.title(title)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    channel.text(message)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return channel.send()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We have now planned our flow and can save it as main.py.</p><u> 4. Cloud-Container </u>With the script created here, we can now create a Docker container, which will give us the ability to run the crawler in the cloud. For this, we create the Dockerfile or take the already existing example.<p>A simple command is enough here to run this example.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$ docker run -it –rm –shm-size=128m docker-selenium-python:latest python ./examples/main.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You can find instructions for setting up in the cloud environment here:</p><ul><li><a href="https://learn.microsoft.com/de-de/azure/container-instances/container-instances-tutorial-prepare-app" target="_blank" rel="noopener noreferrer">Microsoft Azure</a></li><li><a href="https://us-east-1.signin.aws.amazon.com/oauth?SignatureVersion=4&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIAQHJ3VXZJKWI3EBO4&amp;X-Amz-Date=2023-05-15T15%3A08%3A10.140Z&amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEO%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQChMDyBnLd2%2F6pRONs4Qt%2ByvBbsOpAnL9akqgT%2FbmPzHQIgQDYigveW%2FZwaS10R4VZkdtTA08gEFv%2FXedWIz5r%2ByhkqzQMIGBACGgwwMTU2OTQ0MTMzOTQiDHXEpnkLczxPEFM%2B1SqqAzRfwLNltRQTxPe6NJdMLiwSKoLDoKdz0cfX%2B3V1qQ9SLmVKLxC3Ar3a7JNJzQ2P%2Fj7nrb5FGWM2FhQ8GUt6Zr1YE%2F%2FqvVm1%2FESeKDWHlsJMg0fF8IxeY9vQSVPE59zHD4IP94QeLfiHQPY0zO8fIY98FH6SBw18a%2FJh4AbGv20QF92lXwqVVJlmeyfdKdOTP9%2FjPwAZV1F8FItFqkqkOb8r8p8QwvPEDPr%2B0CqOdOQ631qdOtT%2FBYsOcXcvqBxeAyx1ud2SsvHC1bxG7eFdUGPrigT%2B08LU6rWtabEzNFFsVHzYV45K4o56JTO8%2BeFeKgri7N5qAINjmWAKzBRpSvF2zLx8i5Y%2BLYLx278yZwaNRSTCj%2FzaDkI%2BSP1cqU2qLStDbjXD51CrA3RSVxMjUn7%2BqqF48ynxogK2gsPeNAXSpt4RUwen28SINrnzw6ajQHxU3bxKa8pHx4sIe%2Fq6%2BmsHNdwP9EJsQ5WT0Dsd16F29IVrSfOPbN7azqPuCmVT5HmXtC13WsltPEHL4LHYlGCNqWQy2yIe0ivXLdoEmTEl1aIzwUpWCi0uEjDUgYmjBjqhAYubtfW9U3AJzxe55%2FXr2Ps%2FTiqGV8tWTNhFESUbyVKKXPXeFrbvrQd%2BXNUhXekARqS4aqbyiqmNxy3HyoxWFXnQkIrZHNZfj8kORXtj6QpWwGtYi7J5kh9TOAyW1GASQpj5CLuk8LnvsBLsAqmdSmuxD69GwoaZ1%2FqcSd441OA1uIiaYjeVM4MAU7Z%2F5hKmgLFacJZwD7UaHq7BNIjt2YZ8&amp;X-Amz-Signature=88941b4e1ab60b16a86d29aa30169819c908f3b5558268f10040ef6c273940e1&amp;X-Amz-SignedHeaders=host&amp;client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fecs&amp;code_challenge=Rzvs-__JFcYEHVU8L8WkBiXx4NhaNcxiZN2krlbe1XQ&amp;code_challenge_method=SHA-256&amp;redirect_uri=https%3A%2F%2Fus-east-1.console.aws.amazon.com%2Fecs%2Fhome%3Fregion%3Dus-east-1%26state%3DhashArgs%2523%252FgetStarted%26isauthcode%3Dtrue&amp;region=us-east-1&amp;response_type=code&amp;state=hashArgs%23%2FgetStarted" target="_blank" rel="noopener noreferrer">Amazon AWS</a></li><li><a href="https://cloud.google.com/container-registry/docs/pushing-and-pulling?hl=de" target="_blank" rel="noopener noreferrer">Google Cloud Services</a></li></ul>]]></content>
        <category label="Python3" term="Python3"/>
        <category label="Azure" term="Azure"/>
    </entry>
</feed>